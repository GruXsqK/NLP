{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install python-telegram-bot -y\n",
    "# !pip install dialogflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dialogflow\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from telegram import Update\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = open('data/api_token.txt', 'r').read()\n",
    "JSON_PROJECT = \"data/nlp-bot-df-jmyl-63214f5d01e9.json\"\n",
    "\n",
    "DIALOGFLOW_PROJECT_ID = \"nlp-bot-df-jmyl\"\n",
    "DIALOGFLOW_LANGUAGE_CODE = \"ru\"\n",
    "SESSION_ID = \"NLP_GB_project_bot\"\n",
    "\n",
    "WEIGHTS_GEN_MODEL_PATH = os.path.normpath(\"./data/checkpoints\")\n",
    "PATH_TO_TEXT = \"data/comedy.txt\"\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = Updater(token=API_TOKEN, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = JSON_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(PATH_TO_TEXT, 'rb').read().decode(encoding='1251')\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(WEIGHTS_GEN_MODEL_PATH))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            33280     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (1, None, 512)            1182720   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 512)            1575936   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (1, None, 512)            1575936   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 130)            66690     \n",
      "=================================================================\n",
      "Total params: 4,434,562\n",
      "Trainable params: 4,434,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, char2idx, temperature=1):\n",
    "\n",
    "    num_generate = 600\n",
    "\n",
    "    input_eval = [char2idx.get(start_string, 0)]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ' ' + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startCommand(update: Update, context: CallbackContext):\n",
    "    text = \"Добрый день!\\nЯ могу поболтать, а могу сочинить стихотворение в стиле Данте (команда /verse <Первое слово>)\"\n",
    "    update.message.reply_text(text)\n",
    "    \n",
    "\n",
    "def stopCommand(update: Update, context: CallbackContext):\n",
    "    update.message.reply_text('Пока!')\n",
    "\n",
    "\n",
    "def verseCommand(update: Update, context: CallbackContext):\n",
    "    n_lines = 4\n",
    "    text = \" \".join([word for word in update.message.text.split() if word != \"/verse\"])\n",
    "    verse = generate_text(model, start_string=text, char2idx=char2idx, temperature=1).split(\"\\n\")\n",
    "    update.message.reply_text(\"\\n\".join(verse[:n_lines + 1]))\n",
    "    \n",
    "    \n",
    "def textMessage(update: Update, context: CallbackContext):\n",
    "    user_text = ''.join([ch for ch in list(update.message.text) if ch not in string.punctuation])\n",
    "\n",
    "    session_client = dialogflow.SessionsClient()\n",
    "    session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "    text_input = dialogflow.types.TextInput(text=user_text, language_code=DIALOGFLOW_LANGUAGE_CODE)\n",
    "    query_input = dialogflow.types.QueryInput(text=text_input)\n",
    "\n",
    "    try:\n",
    "        response = session_client.detect_intent(session=session, query_input=query_input)\n",
    "    except InvalidArgument:\n",
    "         raise\n",
    "\n",
    "    text = response.query_result.fulfillment_text\n",
    "    if text:\n",
    "        update.message.reply_text(response.query_result.fulfillment_text)\n",
    "    else:\n",
    "        update.message.reply_text('Что?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher.add_handler(CommandHandler(\"start\", startCommand))\n",
    "dispatcher.add_handler(CommandHandler(\"stop\", stopCommand))\n",
    "dispatcher.add_handler(CommandHandler(\"verse\", verseCommand))\n",
    "dispatcher.add_handler(MessageHandler(Filters.text, textMessage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
